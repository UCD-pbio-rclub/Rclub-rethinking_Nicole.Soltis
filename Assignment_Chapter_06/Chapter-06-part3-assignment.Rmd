---
title: "Chapter-06-part3-assingment"
author: "Nicole E Soltis"
date: "May 23, 2016"
output: html_document
---

## 6M2
Model selection: use information criteria to select the model with the most weight - as it will on average make better predictions.
Model averaging: preserve multiple models and uncertainty about models as determined by information criteria - avoid overconfidence in our predictions.

## 6M4 ??
What happens to the effective number of parameters, as measured by DIC or WAIC, as a prior
becomes more concentrated? Why? Perform some experiments, if you are not sure.

## 6HARD
Howell !Kung demography
data and split it into two equally sized data frames

two randomly formed data frames, each with 272 rows
use the cases in d1 to fit models and the cases in d2 to evaluate them

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
d$age <- (d$age - mean(d$age))/sd(d$age)
set.seed( 1000 )
i <- sample(1:nrow(d),size=nrow(d)/2)
d1 <- d[ i , ]
d2 <- d[ -i , ]

names(d1)
#first order model
m1 <- map(
  alist(
    height ~ dnorm( mu , exp(log.sigma) ),
    mu <- a + b1*age
  ) ,
  data=d , start=list(a=a.start,b1=0,log.sigma=sigma.start) )
#second order model
m2 <- map(
  alist(
   height ~ dnorm( mu , exp(log.sigma) ) ,
    mu <- a + b1*age + b2*(age^2)
  ) ,
  data=d , start=list(a=a.start,b1=0,b2=0,log.sigma=sigma.start) )
#third order model
m3 <- map(
  alist(
   height ~ dnorm( mu , exp(log.sigma) ) ,
    mu <- a + b1*age + b2*(age^2) + b3*(age^3)
  ) ,
  data=d , start=list(a=a.start,b1=0,b2=0,b3=0,log.sigma=sigma.start) )
#fourth order model
m4 <- map(
  alist(
   height ~ dnorm( mu , exp(log.sigma) ) ,
    mu <- a + b1*age + b2*(age^2) + b3*(age^3) + b4*(age^4)
  ) ,
  data=d , start=list(a=a.start,b1=0,b2=0,b3=0,b4=0,log.sigma=sigma.start) )
#fifth order model
m5 <- map(
  alist(
   height ~ dnorm( mu , exp(log.sigma) ) ,
    mu <- a + b1*age + b2*(age^2) + b3*(age^3) + b4*(age^4) + b5*(age^5)
  ) ,
  data=d , start=list(a=a.start,b1=0,b2=0,b3=0,b4=0,b5=0,log.sigma=sigma.start) )
#sixth order model
m6 <- map(
  alist(
   height ~ dnorm( mu , exp(log.sigma) ) ,
    mu <- a + b1*age + b2*(age^2) + b3*(age^3) + b4*(age^4) + b5*(age^5) + b6*(age^6)
  ) ,
  data=d , start=list(a=a.start,b1=0,b2=0,b3=0,b4=0,b5=0,b6=0,log.sigma=sigma.start) )

#6H1
compare(m1,m2,m3,m4,m5,m6)

#6H2
ag.seq <- seq(from=-1.45,to=2.61,length.out=30)
d.predict <- list(
  height = rep(0,30), # empty outcome
  age = ag.seq
)
#m1
pred.6h2.m1 <- link( m1 , data=d.predict )
mu.m1 <- apply( pred.6h2.m1 , 2 , mean )
mu.PI.m1 <- apply( pred.6h2.m1 , 2, function(x) PI(x, prob=0.97) )
# plot it all
plot( height ~ age , d , col=rangi2 )
#dashed regression line
lines( ag.seq , mu.m1 , lty=2 )
shade(mu.PI.m1, ag.seq)

#m2
pred.6h2.m2 <- link( m2 , data=d.predict )
mu.m2 <- apply( pred.6h2.m2 , 2 , mean )
mu.PI.m2 <- apply( pred.6h2.m2 , 2, function(x) PI(x, prob=0.97) )
plot( height ~ age , d , col=rangi2 )
lines( ag.seq , mu.m2 , lty=2 )
shade(mu.PI.m2, ag.seq)

#m3
pred.6h2.m3 <- link( m3 , data=d.predict )
mu.m3 <- apply( pred.6h2.m3 , 2 , mean )
mu.PI.m3 <- apply( pred.6h2.m3 , 2, function(x) PI(x, prob=0.97) )
plot( height ~ age , d , col=rangi2 )
lines( ag.seq , mu.m3 , lty=2 )
shade(mu.PI.m3, ag.seq)

#m4
pred.6h2.m4 <- link( m4 , data=d.predict )
mu.m4 <- apply( pred.6h2.m4 , 2 , mean )
mu.PI.m4 <- apply( pred.6h2.m4 , 2, function(x) PI(x, prob=0.97) )
plot( height ~ age , d , col=rangi2 )
lines( ag.seq , mu.m4 , lty=2 )
shade(mu.PI.m4, ag.seq)

#m5
pred.6h2.m5 <- link( m5 , data=d.predict )
mu.m5 <- apply( pred.6h2.m5 , 2 , mean )
mu.PI.m5 <- apply( pred.6h2.m5 , 2, function(x) PI(x, prob=0.97) )
plot( height ~ age , d , col=rangi2 )
lines( ag.seq , mu.m5 , lty=2 )
shade(mu.PI.m5, ag.seq)

#m6
pred.6h2.m6 <- link( m6 , data=d.predict )
mu.m6 <- apply( pred.6h2.m6 , 2 , mean )
mu.PI.m6 <- apply( pred.6h2.m6 , 2 , function(x) PI(x, prob=0.97) )
plot( height ~ age , d , col=rangi2 )
lines( ag.seq , mu.m6 , lty=2 )
shade(mu.PI.m6, ag.seq)

#6H3
d1.ensemble <- ensemble( m1 , m2 , m3 , m4 , m5, m6, data=d.predict )
mu.6h3 <- apply( d1.ensemble$link , 2 , mean )
mu.PI.6h3 <- apply( d1.ensemble$link , 2 , PI )
plot( height ~ age , d , col=rangi2 )
lines( ag.seq , mu.6h3 )
shade( mu.PI.6h3 , ag.seq )

#6H4
#compute test-sample deviance for each model
#log-likelihood of height data
sum( dnorm( d2$height , mu , sigma , log=TRUE ) )
#mu is a vector of predicted means
#sigma is MAP sd

#6H5

#6H6
m6h6 <- map(
  alist(
   height ~ dnorm( mu , exp(log.sigma) ) ,
    mu <- a + b1*age + b2*(age^2) + b3*(age^3) + b4*(age^4) + b5*(age^5) + b6*(age^6)
  ),
  b1 ~ dnorm( 0 , 5 ) ,
  b2 ~ dnorm( 0 , 5 ) ,
  b3 ~ dnorm( 0 , 5 ) ,
  b4 ~ dnorm( 0 , 5 ) ,
  b5 ~ dnorm( 0 , 5 ) ,
  b6 ~ dnorm( 0 , 5 ) ,
  data=d , start=list(a=a.start,log.sigma=sigma.start) )
```

##6H1

model rankings:  m4 > m6 > m5 > m3 = m2 = m1

WAIC weights: 
- m4 = 0.42
- m6 = 0.36
- m5 = 0.21
- m1, m2, m3 = 0

## 6H2
Model 1 and model 2 fit the data poorly; models 4 through 6 predict the data reasonably well.

## 6H3
The averaged predictions have a narrower PI than the highest WAIC model, particularly in the data-sparse region with high ages.

## 6H4
Compute the test-sample deviance for each model. This means calculating deviance, but using
the data in d2 now. 


## 6H5

## 6H6