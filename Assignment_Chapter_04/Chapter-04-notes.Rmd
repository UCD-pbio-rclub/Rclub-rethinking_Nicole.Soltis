---
title: "Chapter-04-notes"
author: "Nicole E Soltis"
date: "March 10, 2016"
output: html_document
---

##4.1
```{r}
pos <- replicate( 1000 , sum( runif(16,-1,1) ) )
hist(pos)
plot(density(pos))
```

##4.2
```{r}
#random growth: product of 12 random numbers between 0 and 0.1
#multiplying small  numbers is approximately the same as addition
prod( 1 + runif(12,0,0.1) )
```

##4.3
```{r}
#distribution of random products
growth <- replicate( 10000 , prod( 1 + runif(12,0,0.1) ) )
dens( growth , norm.comp=TRUE )
```

##4.4
Small effects multiplied are approximately additive, stabilize on Gaussian dist.
```{r}

big <- replicate( 10000 , prod( 1 + runif(12,0,0.5) ) )
small <- replicate( 10000 , prod( 1 + runif(12,0,0.01) ) )
```

##4.4
Large deviates multiplied are log-normal
```{r}
log.big <- replicate( 10000 , log(prod(1 + runif(12,0,0.5))) )
```

##4.5
```{r}
log.big <- replicate( 10000 , log(prod(1 + runif(12,0,0.5))) )
```

##4.6
grid approximation: same as Bayes' theorem incorporating model definition
```{r}
w <- 6; n <- 9;
p_grid <- seq(from=0,to=1,length.out=100)
posterior <- dbinom(w,n,p_grid)*dunif(p_grid,0,1)
posterior <- posterior/sum(posterior)
```

##4.7 - 4.10
```{r}
library(rethinking)
data(Howell1)
d <- Howell1

#4.8
str(d)

#4.9
d$height #extract column height from data frame d. a vector
#data frames are a special list
d[[1]] #gives you first element in list (first column in case of df)

#4.10
#only adults
#d[row,col]
d2 <- d[ d$age >= 18 , ]

#distribution of heights
dens(d2$height)

```

##4.11 prior for mean adult height - with max, min, mean, sd
```{r}
curve( dnorm( x , 178 , 20 ) , from=100 , to=250 )
```

##4.12 prior for sd adult height - with bounds, max, min
#r random from a prior. d samples from a distribution.
```{r}
curve( dunif( x , 0 , 50 ) , from=-10 , to=60 )
```

##4.13 simulate height data by sampling from the prior
```{r}
sample_mu <- rnorm( 1e4 , 178 , 20 ) #number of samples, mean, sd
sample_sigma <- runif( 1e4 , 0 , 50 ) #samples, low bound, upper bound
prior_h <- rnorm( 1e4 , sample_mu , sample_sigma ) #number of samples, mean, sd
dens( prior_h )
```

##4.14 to 4.15
```{r}
#grid approximation  golem of the posterior distribution
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]

mu.list <- seq( from=140, to=160 , length.out=200 )
sigma.list <- seq( from=4 , to=9 , length.out=200 )
post <- expand.grid( mu=mu.list , sigma=sigma.list )
post$LL <- sapply( 1:nrow(post) , function(i) sum( dnorm(
d2$height ,
mean=post$mu[i] ,
sd=post$sigma[i] ,
log=TRUE ) ) )
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE )
post$prob <- exp( post$prod - max(post$prod) )

#4.15 contour plot of posterior distribution
contour_xyz( post$mu , post$sigma , post$prob )

#4.16 heat map of posterior distribution
image_xyz( post$mu , post$sigma , post$prob )

#4.17 randomly sample parameter values from the posterior
sample.rows <- sample( 1:nrow(post) , size=1e4 , replace=TRUE , prob=post$prob )
sample.mu <- post$mu[ sample.rows ]
sample.sigma <- post$sigma[ sample.rows ]

#4.18 look at samples
#col.alpha makes colors transparent
plot( sample.mu , sample.sigma , cex=0.5 , pch=16, col=col.alpha(rangi2,0.1) )

#4.19 characterize shapes of marginal posterior densities
#marginal = averaged over other parameters
dens( sample.mu ) #mu sampled from a random distribution
dens( sample.sigma )

#4.20 summarize width using HDPI of densities
#not centered- appropriate for skewed distributions
#narrowest interval containing specified probability (89% by default)
HPDI(sample.mu)
HPDI(sample.sigma)

#4.21 subsample 20 heights from the original list
#keep in mind that right skew in sd is common
d3 <- sample( d2$height , size=20 )

#4.22 grid approximation of the subsample from 4.21
mu.list <- seq( from=150, to=170 , length.out=200 )
sigma.list <- seq( from=4 , to=20 , length.out=200 )
post2 <- expand.grid( mu=mu.list , sigma=sigma.list )
post2$LL <- sapply( 1:nrow(post2) , function(i)
sum( dnorm( d3 , mean=post2$mu[i] , sd=post2$sigma[i] ,
log=TRUE ) ) )
post2$prod <- post2$LL + dnorm( post2$mu , 178 , 20 , TRUE ) +
dunif( post2$sigma , 0 , 50 , TRUE )
post2$prob <- exp( post2$prod - max(post2$prod) )
sample2.rows <- sample( 1:nrow(post2) , size=1e4 , replace=TRUE ,
prob=post2$prob )
sample2.mu <- post2$mu[ sample2.rows ]
sample2.sigma <- post2$sigma[ sample2.rows ]
plot( sample2.mu , sample2.sigma , cex=0.5 ,
col=col.alpha(rangi2,0.1) ,
xlab="mu" , ylab="sigma" , pch=16 )

#4.23 marginal posterior density of sd averaged over mu
dens( sample2.sigma , norm.comp=TRUE )
#does not match normal approximation --> not gaussian

```

##4.24 - 4.36 MAP and quadratic approximation
```{r}
#the posterior's peak is at maximum a posteriori estimate (MAP)
#use the quadratic approximation of the posterior distribution at the MAP peak to estimate the posterior's shape

#4.24 load the data, select only adults
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]

#4.25 make alist of 3 equations to define the model
flist <- alist(
height ~ dnorm( mu , sigma ) ,
mu ~ dnorm( 178 , 20 ) ,
sigma ~ dunif( 0 , 50 )
)

#4.26 fit the model of the data
m4.1 <- map( flist , data=d2 )

#4.27 examine fit map model (89% interval by default)
precis( m4.1 )
#95% interval
precis(m4.1,prob=0.95)

#4.28 give map starting values for mu and sigma
#list evaluates the code inside, alist does not
start <- list(
mu=mean(d2$height),
sigma=sd(d2$height)
)

#4.29 try it again with more informative priors
m4.2 <- map(
alist(
height ~ dnorm( mu , sigma ) ,
mu ~ dnorm( 178 , 0.1 ) ,
sigma ~ dunif( 0 , 50 )
) ,
data=d2 )
precis( m4.2 )

#4.30
#variance-covariance matrix!
#the list of means and a matrix of variances and covariances that are sufficient to describe a multi-dimensional Gaussian distribution
vcov( m4.1 )

#4.31 decomposition into
#(1) a vector of variances for the parameters and 
#(2) a correlation matrix that tells us how changes in any parameter lead to correlated changes in the others.
diag( vcov( m4.1 ) )
cov2cor( vcov( m4.1 ) )
#covariance: so can change sigma by changing priors of mu

#4.32 sample vectors of values from multidimensional gaussian
#sample 10k times
library(rethinking)
post <- extract.samples( m4.1 , n=1e4 )
head(post)

#4.33
#confirm that mean and sd of mu and sigma sampled from the posterior are close to the previous map values
precis(post)

#4.34
#mvnorm is a multidimensional rnorm
#simulates random vectors of multivariate Gaussian values
library(MASS)
post <- mvrnorm( n=1e4 , mu=coef(m4.1) , Sigma=vcov(m4.1) )

#4.35
#log(sigma) is more normal than sigma
m4.1_logsigma <- map(
alist(
height ~ dnorm( mu , exp(log_sigma) ) ,
mu ~ dnorm( 178 , 20 ) ,
log_sigma ~ dnorm( 2 , 10 )
) , data=d2 )

#4.36
#exp sigma to get distribution on natural scale
post <- extract.samples( m4.1_logsigma )
sigma <- exp( post$log_sigma )
```

#Section 4.4
##4.37
```{r}
#load the data, select only adults
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]
plot( d2$height ~ d2$weight )

#thought on utility of what we've learned so far:
  #impute missing values by randomly selecting a value from the distribution, in proportion to its probability. AS OPPOSED TO just using a mean!
```

##4.4.2
```{r}
height ~ dnorm(mu, sigma)
mu <- a + b*weight
a ~ dnorm(156, 100)
b ~ dnorm(0, 10)
sigma ~ dunif(0, 50)

#4.38
#build MAP model fit
# load data again, since it's a long way back
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]
# fit model
m4.3 <- map(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*weight ,
a ~ dnorm( 156 , 100 ) ,
b ~ dnorm( 0 , 10 ) ,
sigma ~ dunif( 0 , 50 )
) ,
data=d2 )

#4.39
#linear model within the likelihood definition
m4.3 <- map(
alist(
height ~ dnorm( a + b*weight , sigma ) ,
a ~ dnorm( 178 , 100 ) ,
b ~ dnorm( 0 , 10 ) ,
sigma ~ dunif( 0 , 50 )
) ,
data=d2 )

#4.40
precis(m4.3)
#beta slope: 0.90 unit change in height per 1 unit change in weight
#alpha intercept: person of weight 0 should be 114 cm tall

#4.41
precis( m4.3 , corr=TRUE )
#correlation matrix among parameters
#same as:
cov2cor(vcov(m4.3))
#slope and intercept are highly negatively correlated- challenge for model fitting

#center the data to avoid negative correlation
#4.42
d2$weight.c <- d2$weight - mean(d2$weight)

#average is now 0
mean(d2$weight.c)

#rerun the model on centered data
#4.43
m4.4 <- map(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*weight.c ,
a ~ dnorm( 178 , 100 ) ,
b ~ dnorm( 0 , 10 ) ,
sigma ~ dunif( 0 , 50 )
) ,
data=d2 )

#4.44
precis( m4.4 , corr=TRUE )
#alpha estimate is now average height
#correlation now 0
#intercept as: expected value of outcome when predictor is at its average value

#4.45
#superimpose MAP values for mean height over actual data
#pulled numbers straight from fit model
plot( height ~ weight , data=d2 )
abline( a=coef(m4.3)["a"] , b=coef(m4.3)["b"] )

#4.46 sample from the posterior
post <- extract.samples( m4.3 )
#4.47 inspect first 5 rows
post[1:5,]

#4.48 extract first 10 cases in d2 and estimate model
N <- 10
dN <- d2[ 1:N , ]
mN <- map(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*weight ,
a ~ dnorm( 178 , 100 ) ,
b ~ dnorm( 0 , 10 ) ,
sigma ~ dunif( 0 , 50 )
) , data=dN )

#4.49
# extract 20 samples from the posterior
post <- extract.samples( mN , n=20 )
# display raw data and sample size
plot( dN$weight , dN$height ,
xlim=range(d2$weight) , ylim=range(d2$height) ,
col=rangi2 , xlab="weight" , ylab="height" )
mtext(concat("N = ",N))
# plot the lines, with transparency
for ( i in 1:20 )
abline( a=post$a[i] , b=post$b[i] , col=col.alpha("black",0.3) )

#4.50
mu_at_50 <- post$a + post$b * 50

#4.51
dens( mu_at_50 , col=rangi2 , lwd=2 , xlab="mu|weight=50" )

#4.52
HPDI( mu_at_50 , prob=0.89 )

#4.53
#link takes map model fit, samples from post, computes mu for each case in sample
mu <- link( m4.3 )
str(mu)

#4.54
# define sequence of weights to compute predictions for
# these values will be on the horizontal axis
weight.seq <- seq( from=25 , to=70 , by=1 )
# use link to compute mu
# for each sample from posterior
# and for each weight in weight.seq
mu <- link( m4.3 , data=data.frame(weight=weight.seq) )
str(mu)

#4.55
# use type="n" to hide raw data
plot( height ~ weight , d2 , type="n" )
# loop over samples and plot each mu value
for ( i in 1:100 )
points( weight.seq , mu[i,] , pch=16 , col=col.alpha(rangi2,0.1) )

#4.56
# summarize the distribution of mu
mu.mean <- apply( mu , 2 , mean )
mu.HPDI <- apply( mu , 2 , HPDI , prob=0.89 )

#4.57
# plot raw data
# fading out points to make line and interval more visible
plot( height ~ weight , data=d2 , col=col.alpha(rangi2,0.5) )
# plot the MAP line, aka the mean mu for each weight
lines( weight.seq , mu.mean )
# plot a shaded region for 89% HPDI
shade( mu.HPDI , weight.seq )

#4.58
post <- extract.samples(m4.3)
mu.link <- function(weight) post$a + post$b*weight
weight.seq <- seq( from=25 , to=70 , by=1 )
mu <- sapply( weight.seq , mu.link )
mu.mean <- apply( mu , 2 , mean )
mu.HPDI <- apply( mu , 2 , HPDI , prob=0.89 )

#4.59
sim.height <- sim( m4.3 , data=list(weight=weight.seq) )
str(sim.height)

#4.60
height.PI <- apply( sim.height , 2 , PI , prob=0.89 )

#4.61
# plot raw data
plot( height ~ weight , d2 , col=col.alpha(rangi2,0.5) )
# draw MAP line
lines( weight.seq , mu.mean )
# draw HPDI region for line
shade( mu.HPDI , weight.seq )
# draw PI region for simulated heights
shade( height.PI , weight.seq )

#4.62
sim.height <- sim( m4.3 , data=list(weight=weight.seq) , n=1e4 ) 4.62
height.PI <- apply( sim.height , 2 , PI , prob=0.89 )

#4.63
post <- extract.samples(m4.3)
weight.seq <- 25:70
sim.height <- sapply( weight.seq , function(weight)
rnorm(
n=nrow(post) ,
mean=post$a + post$b*weight ,
sd=post$sigma ) )
height.PI <- apply( sim.height , 2 , PI , prob=0.89 )

```

#section 4.5
```{r}
#4.64
library(rethinking)
data(Howell1)
d <- Howell1
str(d)

#4.65 standardize weight
d$weight.s <- ( d$weight - mean(d$weight))/sd(d$weight)

#4.66
d$weight.s2 <- d$weight.s^2
m4.5 <- map(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b1*weight.s + b2*weight.s2 ,
a ~ dnorm( 178 , 100 ) ,
b1 ~ dnorm( 0 , 10 ) ,
b2 ~ dnorm( 0 , 10 ) ,
sigma ~ dunif( 0 , 50 )
) ,
data=d )

#4.67
precis(m4.5)

#4.68
weight.seq <- seq( from=-2.2 , to=2 , length.out=30 )
pred_dat <- list( weight.s=weight.seq , weight.s2=weight.seq^2 )
mu <- link( m4.5 , data=pred_dat )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI , prob=0.89 )
sim.height <- sim( m4.5 , data=pred_dat )
height.PI <- apply( sim.height , 2 , PI , prob=0.89 )

#4.69
plot( height ~ weight.s , d , col=col.alpha(rangi2,0.5) ) 
lines( weight.seq , mu.mean )
shade( mu.PI , weight.seq )
shade( height.PI , weight.seq )

#4.70
d$weight.s3 <- d$weight.s^3
m4.6 <- map(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b1*weight.s + b2*weight.s2 + b3*weight.s3 ,
a ~ dnorm( 178 , 100 ) ,
b1 ~ dnorm( 0 , 10 ) ,
b2 ~ dnorm( 0 , 10 ) ,
b3 ~ dnorm( 0 , 10 ) ,
sigma ~ dunif( 0 , 50 )
) ,
data=d )

#4.71
plot( height ~ weight.s , d , col=col.alpha(rangi2,0.5) , xaxt="n" )

#4.72
at <- c(-2,-1,0,1,2)
labels <- at*sd(d$weight) + mean(d$weight)
axis( side=1 , at=at , labels=round(labels,1) )
```

#additional notes
QTL mapping built on regressions
frequentist linear regression with 2 categories = identical to t-test
